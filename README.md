# ğŸ  House Price Prediction â€” v2 Enhanced ML Pipeline

This repository implements an **advanced, modular machine learning pipeline** for predicting median house prices in California.  
It represents the **second version (v2)** of the project, introducing engineered features, regularized linear models, cross-validation, hyperparameter tuning, and a custom Gradient Descent implementation built from scratch.

---

## ğŸ¯ Project Overview

The goal of this version is to:
- Build a **fully modular, extensible machine learning pipeline** for structured tabular data.
- Introduce **feature engineering and standardization** to improve model stability and performance.
- Implement and compare **multiple linear models**, including OLS, Ridge, Lasso, and a custom Gradient Descent Regressor built from scratch.
- Evaluate model robustness through **5-fold cross-validation** and targeted hyperparameter tuning.
- Establish a **reproducible training workflow** that cleanly separates preprocessing, model training, evaluation, and inference.

This version focuses on **engineering best practices**, enabling experimentation, modularity, and reliable performance benchmarking across models.

---

## ğŸ”„ Whatâ€™s New in v2 (Compared to v1)

A quick overview of improvements introduced in Version 2:

| Aspect | v1 Baseline | v2 Enhanced Pipeline |
|--------|-------------|----------------------|
| Feature Engineering | Minimal | Full transformations + scaling |
| Models | OLS only | GD (custom), OLS, Ridge, Lasso |
| Cross-Validation | No | Yes â€” 5-fold |
| Pipeline | Notebook-only | Modular Python pipeline (`src/`) |
| Performance | Higher RMSE | Lower RMSE after FE + regularization |

---

## âœ¨ Key Features

- **Modular ML pipeline** (`src/` folder) for clean separation of preprocessing, training, evaluation, and utilities.
- **Feature engineering & standardization**, ensuring consistent transformations across training and inference.
- **Multiple linear models**:
  - OLS (Linear Regression)
  - Ridge Regression (L2)
  - Lasso Regression (L1)
- **Custom Gradient Descent Regressor** implemented from scratch with configurable learning rate, iterations, and convergence tracking.
- **5-fold Cross-Validation** for assessing model stability and variance.
- **Hyperparameter tuning** for regularized models using a simple grid search workflow.
- **Reproducible training pipeline** (`python -m src.training_pipeline`) for end-to-end training and evaluation.
- **Five structured Jupyter notebooks** documenting the full development process:
  - Feature engineering  
  - Model experiments  
  - Gradient Descent implementation  
  - Cross-validation  
  - End-to-end demonstration

---

## ğŸ§± Repository Structure
```
house-price-ml-v2/
â”‚
â”œâ”€â”€ data/                                  # Local dataset storage (not included in Git intentionally for privacy / size)
â”‚   â”œâ”€â”€ processed/                         # Cleaned / transformed data (not saved in this project; kept ephemeral)
â”‚   â””â”€â”€ raw/                               # Unmodified input data (as downloaded)
â”‚   
â”œâ”€â”€ models/                                # Saved model artifacts (not included in Git to avoid large files and ensure reproducible training)
â”‚
â”œâ”€â”€ notebooks/                             # Full development workflow (v2 notebooks)
â”‚   â”œâ”€â”€ 01_exploration.ipynb               # Initial EDA, data inspection, distributions, correlations
â”‚   â”œâ”€â”€ 02_model_evaluation.ipynb          # Training and evaluating the custom Gradient Descent Regressor
â”‚   â”œâ”€â”€ 03_sklearn_baseline.ipynb          # Baseline Linear Regression using scikit-learn (LinearRegression)
â”‚   â”œâ”€â”€ 04_cross_validation.ipynb          # 5-fold CV comparing OLS, Ridge, and Lasso models, stability analysis
â”‚   â””â”€â”€ 05_pipeline_demo.ipynb             # End-to-end demonstration of the modular training pipeline
â”‚
â”œâ”€â”€ reports/                               # Project documentation and reports
â”‚   â”œâ”€â”€ metrics/
â”‚   â”œâ”€â”€ plots/
â”‚   â””â”€â”€ report.md                          # Detailed technical write-up for Version 2
â”‚
â”œâ”€â”€ src/                                   # Modular machine learning pipeline (from scratch)
â”‚   â”œâ”€â”€ __init__.py                        # Marks directory as a Python package
â”‚   â”œâ”€â”€ config.py                          # Centralized configuration / constants
â”‚   â”œâ”€â”€ data_loader.py                     # Data loading utilities for datasets
â”‚   â”œâ”€â”€ evaluation.py                      # Metrics, scoring utilities, model evaluation logic
â”‚   â”œâ”€â”€ feature_engineering.py             # Data cleaning, feature transformations, scaling logic
â”‚   â”œâ”€â”€ gradient_descent.py                # Custom Gradient Descent Regressor
â”‚   â”œâ”€â”€ hyperparameter_tuning.py           # Grid search utilities
â”‚   â”œâ”€â”€ model_io.py                        # Save/load functions for pipeline components and artifacts
â”‚   â”œâ”€â”€ preprocessing.py                   # Preprocessing utilities (standardization)
â”‚   â””â”€â”€ train.py                           # End-to-end pipeline (run via: python3 -m src.train)
â”‚
â”œâ”€â”€ .gitignore
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

> ğŸ—’ï¸ **Note:**  
> Version 2 uses a **fully modular architecture** inside `src/`, and the `notebooks/` directory follows a clean, sequential workflow from exploration â†’ baselines â†’ cross-validation â†’ final pipeline.
> `data/processed/` â€” holds intermediate transformed data during notebook work, but **processed outputs are not persisted** since transformations are reproducible through the pipeline.

---

## ğŸ§° Run Locally

You can run this project on your machine using **Python 3.11** and `venv`.

### 1ï¸âƒ£ Clone the repository
```bash
git clone git@github.com:florykhan/house-price-ml-v2.git
cd house-price-ml-v2
```

### 2ï¸âƒ£ Create and activate a virtual environment
```bash
python3 -m venv venv
source venv/bin/activate      # macOS/Linux
venv\Scripts\activate         # Windows
```
### 3ï¸âƒ£ Install dependencies
```bash
pip3 install -r requirements.txt
```

### 4ï¸âƒ£ Add the dataset
Place `housing.csv` inside the `data/raw/` folder:
```bash
house-price-ml-v2/data/raw/housing.csv
```
> âš ï¸ **Note:**  Processed data is not saved in this project. All transformations are applied dynamically through the pipeline.

### 5ï¸âƒ£ Run the training pipeline (required before running notebooks)
This step is essential â€” the training pipeline performs all preprocessing, feature engineering, and model training needed for the notebooks to run correctly.

```bash
python3 -m src.train
```

### 6ï¸âƒ£ Run the notebooks
Launch Jupyter and open the notebooks:
```bash
jupyter notebook
```

Recommended order:
- `01_exploration.ipynb` â€” data exploration
- `02_model_evaluation.ipynb` â€” custom Gradient Descent
- `03_sklearn_baseline.ipynb` â€” sklearn LinearRegression
- `04_cross_validation.ipynb` â€” OLS/Ridge/Lasso CV comparison
- `05_pipeline_demo.ipynb` â€” full end-to-end pipeline demo

---

## ğŸ“ˆ Results (Summary)

### Custom Gradient Descent Regressor
- Converged in ~1500 iterations  
- Test RMSE: ~75,000 USD  
- Test RÂ²: ~0.58  

### Best overall model (from report):
- Ridge Regression with Î± = 1.0  
- Test RMSE: ~73,000 USD  
- Test RÂ²: ~0.60  

Do NOT put full tables â€” those belong in the report. -> Ket takeaways (1-2 bullets)

8. Link to full report

Link to report.md:

For the full technical explanation, see report.md

This is where you point anyone who wants deep detail.

9. Future Work
in the next project combine hyperparameter tuning with cv ğŸ”¥
---

## ğŸ§  Tech Stack

- **Language:** Python 3.11  
- **Core Libraries:**  
  - `pandas`, `numpy`, `matplotlib`  
  - `scikit-learn`
- **Custom Components:**  
  - Custom Gradient Descent Regressor  
  - Reusable feature engineering, evaluation, and tuning modules (`src/` folder)
  - End-to-end training pipeline (`python3 -m src.train`)
- **Environment:** Jupyter Notebook / VS Code
- **Version Control:** Git + GitHub (SSH configured)

---

## ğŸ§¾ License
MIT License â€” feel free to use and modify with attribution.
See the [`LICENSE`](./LICENSE) file for full details.

---

## ğŸ‘¤ Author
**Ilian Khankhalaev**  
_BSc Computing Science, Simon Fraser University_  
ğŸ“ Vancouver, BC  |  [florykhan@gmail.com](mailto:florykhan@gmail.com)  |  [GitHub](https://github.com/florykhan)  |  [LinkedIn](https://www.linkedin.com/in/ilian-khankhalaev/)
